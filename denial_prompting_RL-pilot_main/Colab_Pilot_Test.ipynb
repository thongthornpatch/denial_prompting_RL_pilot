{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denial Prompting RL - Google Colab Pilot Test\n",
    "- Model: GPT-2 (124M parameters)\n",
    "- Data: NeoCoder dataset (subset of 10 problems)\n",
    "- Training: 50 GRPO steps with gradient updates\n",
    "- GPU: Google Colab T4 (free)\n",
    "\n",
    "**Runtime:** Around 5 minutes (check pipeline before deploying to NSCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Runtime\n",
    "Enable GPU in Colab (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"GPU not available. Enable in settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository (replace with your actual repo URL)\n",
    "!git clone https://github.com/thongthornpatch/denial_prompting_RL_pilot.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers>=4.35.0 datasets>=2.14.0 RestrictedPython>=6.0 tqdm pyyaml\n",
    "print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download NeoCoder Dataset (use just subset in this pilot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NeoCoder dataset\n",
    "!python scripts/download_neocoder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all components\n",
    "!python scripts/test_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pilot Training (50 steps)\n",
    "- Load GPT-2 model\n",
    "- Generate code\n",
    "- Compute rewards\n",
    "- Update model weights using GRPO\n",
    "- Save metrics and checkpoints\n",
    "\n",
    "**Runtime:** around 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run actual training with real model\n",
    "!python scripts/train.py \\\n",
    "    --config configs/config_colab.yaml \\\n",
    "    --output_dir outputs/colab_pilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load training metrics\n",
    "with open('outputs/colab_pilot/metrics.json') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "# Extract data\n",
    "steps = sorted([int(k) for k in metrics.keys()])\n",
    "rewards = [metrics[str(s)]['mean_reward'] for s in steps]\n",
    "violations = [metrics[str(s)]['mean_violations'] for s in steps]\n",
    "success_rates = [metrics[str(s)]['success_rate'] for s in steps]\n",
    "losses = [metrics[str(s)]['loss'] for s in steps]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal steps: {len(steps)}\")\n",
    "print(f\"\\nReward Statistics:\")\n",
    "print(f\"  Initial reward: {rewards[0]:.3f}\")\n",
    "print(f\"  Final reward: {rewards[-1]:.3f}\")\n",
    "print(f\"  Change: {rewards[-1] - rewards[0]:+.3f}\")\n",
    "print(f\"  Max reward: {max(rewards):.3f}\")\n",
    "\n",
    "# Compare first vs second half\n",
    "mid = len(rewards) // 2\n",
    "first_half = sum(rewards[:mid]) / mid\n",
    "second_half = sum(rewards[mid:]) / (len(rewards) - mid)\n",
    "print(f\"\\nLearning Progress:\")\n",
    "print(f\"  First half average: {first_half:.3f}\")\n",
    "print(f\"  Second half average: {second_half:.3f}\")\n",
    "if second_half > first_half:\n",
    "    print(f\"Improving! (+{second_half - first_half:.3f})\")\n",
    "else:\n",
    "    print(f\"Declining ({second_half - first_half:.3f})\")\n",
    "\n",
    "print(f\"\\nViolations:\")\n",
    "print(f\"  Average: {sum(violations)/len(violations):.2f}\")\n",
    "print(f\"  Initial: {violations[0]:.2f}\")\n",
    "print(f\"  Final: {violations[-1]:.2f}\")\n",
    "\n",
    "print(f\"\\nSuccess Rate:\")\n",
    "print(f\"  Average: {sum(success_rates)/len(success_rates):.1%}\")\n",
    "print(f\"  Initial: {success_rates[0]:.1%}\")\n",
    "print(f\"  Final: {success_rates[-1]:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualise Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Reward over time\n",
    "axes[0, 0].plot(steps, rewards, marker='o', linewidth=2, markersize=4)\n",
    "axes[0, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_title('Mean Reward Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Step')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Violations over time\n",
    "axes[0, 1].plot(steps, violations, marker='o', color='red', linewidth=2, markersize=4)\n",
    "axes[0, 1].set_title('Constraint Violations Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Step')\n",
    "axes[0, 1].set_ylabel('Violations per Solution')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Success rate over time\n",
    "axes[1, 0].plot(steps, [s*100 for s in success_rates], marker='o', color='green', linewidth=2, markersize=4)\n",
    "axes[1, 0].set_title('Success Rate Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Step')\n",
    "axes[1, 0].set_ylabel('Success Rate (%)')\n",
    "axes[1, 0].set_ylim([0, 105])\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Training loss over time\n",
    "axes[1, 1].plot(steps, losses, marker='o', color='purple', linewidth=2, markersize=4)\n",
    "axes[1, 1].set_title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Step')\n",
    "axes[1, 1].set_ylabel('Loss')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/colab_pilot/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training curves saved to outputs/colab_pilot/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inspect Code Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example of what the model generates\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from models.model_wrapper import ModelWrapper\n",
    "\n",
    "# Load the trained model\n",
    "print(\"Loading trained model from checkpoint\")\n",
    "model = ModelWrapper(\n",
    "    model_name=\"outputs/colab_pilot/checkpoints/final_model\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "# Test prompt\n",
    "test_prompt = \"\"\"# Write a function that returns the sum of two numbers\n",
    "# DO NOT use: while loop\n",
    "def solve(a, b):\n",
    "    \"\"\"\n",
    "\n",
    "print(\"\\nGenerating code from trained model...\")\n",
    "print(\"=\"*80)\n",
    "print(\"PROMPT:\")\n",
    "print(test_prompt)\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated solutions:\\n\")\n",
    "\n",
    "# Generate 3 solutions\n",
    "solutions = model.generate(\n",
    "    prompt=test_prompt,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.8,\n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "for i, sol in enumerate(solutions, 1):\n",
    "    print(f\"Solution {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(test_prompt + sol)\n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interpretation and Next Steps:\n",
    "\n",
    "If results look good, then deploy to NSCC for full training (5000 steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Download Results\n",
    "\n",
    "Download the results to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip results\n",
    "!zip -r colab_pilot_results.zip outputs/colab_pilot/\n",
    "\n",
    "# Download in Colab\n",
    "from google.colab import files\n",
    "files.download('colab_pilot_results.zip')\n",
    "\n",
    "print(\"Ready\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
